{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PROYECTO COVID-19**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la funcion para leer imagenes y aumentar el tamaño de nuestro conjunto de datos, utilizando:\n",
    "- Ruido Gaussiano\n",
    "- Volteando verticalmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lectura(subdirectorio,fichero,path=\"Dataset/\"):\n",
    "    if(os.path.exists(path+subdirectorio)):\n",
    "        listaImagenes = os.listdir(path+subdirectorio)\n",
    "        datos = []\n",
    "\n",
    "        for imagen in listaImagenes:\n",
    "            datos.append(cv2.imread(path+subdirectorio+imagen,0))\n",
    "        if(os.path.isfile(path+fichero)):\n",
    "            with open(path+fichero) as fp: \n",
    "                salidas = fp.read().splitlines()\n",
    "            return np.array(datos), np.array(salidas)\n",
    "        else:\n",
    "            print(\"¡Error! El fichero de salidas no existe\")\n",
    "    else:\n",
    "        print(\"¡Error! El directorio no existe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tratamiento(pathImagenes=\"Data/\", dx=256, dy=256, noiseX=5, noiseY=10):\n",
    "    if(os.path.exists(pathImagenes)):\n",
    "        resultado = []\n",
    "        listaImagenes = os.listdir(pathImagenes)\n",
    "\n",
    "        #Realizar un data augmentation para aumentar los datos del dataset:\n",
    "        gaussian_noise = iaa.AdditiveGaussianNoise(noiseX, noiseY)\n",
    "        flip_vr=iaa.Fliplr(p=1.0)\n",
    "\n",
    "        for imagen in listaImagenes:\n",
    "            Xray = cv2.resize(cv2.imread(pathImagenes+imagen,0),(dx, dy))\n",
    "            resultado.append(Xray)\n",
    "            resultado.append(gaussian_noise.augment_image(Xray))\n",
    "            resultado.append(flip_vr.augment_image(Xray))\n",
    "\n",
    "        return resultado\n",
    "    else:\n",
    "        print(\"¡Error! El path especificado no ha sido encontrado\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una funcion para hacer el particionamiento de los datos en train, test y val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def particionamiento(listaDatos, train_percent=.6, validate_percent=.2, seed=0):\n",
    "    np.random.seed(seed)\n",
    "    listaTrain=[]\n",
    "    listaTest=[]\n",
    "    listaVal=[]\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    y_val = []\n",
    "    for i,lista in enumerate(listaDatos):\n",
    "        lista = np.array(lista)\n",
    "        perm = np.random.permutation(len(lista))\n",
    "        m = len(lista)\n",
    "        train_end = int(train_percent * m)\n",
    "        val_end = int(validate_percent * m) + train_end\n",
    "        train = lista[perm[:train_end]]\n",
    "        val = lista[perm[train_end:val_end]]\n",
    "        test = lista[perm[val_end:]]\n",
    "        listaTrain.extend(train)\n",
    "        listaTest.extend(test)\n",
    "        listaVal.extend(val)\n",
    "        y_train.extend(list([i]*len(train)))\n",
    "        y_test.extend(list([i]*len(test)))\n",
    "        y_val.extend(list([i]*len(val)))\n",
    "    \n",
    "    return listaTrain, listaTest, listaVal, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def almacenaImagenes(train,test,val,y_train,y_test,y_val,path=\"Dataset/\"):\n",
    "    if(os.path.exists(path)):\n",
    "        try:\n",
    "            shutil.rmtree(path,ignore_errors=True)\n",
    "            \n",
    "        except OSError as e:\n",
    "            print(\"¡Error! No se ha podido eliminar el directorio\")\n",
    "    \n",
    "    os.mkdir(path, 0o7777)\n",
    "    os.mkdir(path+\"train/\",0o7777)\n",
    "    os.mkdir(path+\"val/\",0o7777)\n",
    "    os.mkdir(path+\"test/\",0o7777)\n",
    "    \n",
    "    f = open(path+\"train.txt\", \"w\")\n",
    "    for i,imagen in enumerate(train):\n",
    "        cv2.imwrite(path+\"train/Train-\"+str(i)+\".png\",imagen)\n",
    "        f.write(str(y_train[i])+\"\\n\")\n",
    "    f.close()\n",
    "    \n",
    "    f = open(path+\"test.txt\", \"w\")\n",
    "    for i,imagen in enumerate(test):\n",
    "        cv2.imwrite(path+\"test/Test-\"+str(i)+\".png\",imagen)\n",
    "        f.write(str(y_test[i])+\"\\n\")\n",
    "    f.close()\n",
    "    \n",
    "    f = open(path+\"val.txt\", \"w\")\n",
    "    for i,imagen in enumerate(val):\n",
    "        cv2.imwrite(path+\"val/Val-\"+str(i)+\".png\",imagen)\n",
    "        f.write(str(y_val[i])+\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pretratamiento de imagenes y almacenamiento de las mismas:\n",
    "listaCOVID = tratamiento(pathCovid)\n",
    "listaNORMAL = tratamiento(pathNormal)\n",
    "listaVIRAL = tratamiento(pathViral)\n",
    "\n",
    "listaDatos = [listaCOVID, listaNORMAL, listaVIRAL] \n",
    "train, test, val, y_train, y_test, y_val = particionamiento(listaDatos)\n",
    "\n",
    "almacenaImagenes(train,test,val,y_train,y_test,y_val,pathImagenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julen\\Anaconda3\\envs\\py37machlearn\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\julen\\Anaconda3\\envs\\py37machlearn\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "pathCovid = \"Data/COVID-19/\"\n",
    "pathNormal = \"Data/NORMAL/\"\n",
    "pathViral = \"Data/Viral Pneumonia/\" \n",
    "pathImagenes= \"Dataset/\"\n",
    "fichero_train= \"train.txt\"\n",
    "fichero_test= \"test.txt\"\n",
    "fichero_val= \"val.txt\"\n",
    "dx=256 \n",
    "dy=256\n",
    "\n",
    "train, y_train = lectura(\"train/\",fichero_train,pathImagenes)\n",
    "val,y_val = lectura(\"val/\",fichero_val,pathImagenes)\n",
    "test, y_test = lectura(\"test/\",fichero_test,pathImagenes)\n",
    "\n",
    "#Hacemos reshape de los datos para dejarlos en las dimensiones correctas(2D):\n",
    "Xtrain = np.reshape(train, (train.shape[0], dx*dy))\n",
    "Xtest = np.reshape(test, (test.shape[0], dx*dy))\n",
    "Xval = np.reshape(val, (val.shape[0], dx*dy))\n",
    "\n",
    "##Comprobación de las características y selección:\n",
    "Kbest = SelectKBest(f_classif) #Generamos el objeto SelectKBest\n",
    "Kbest.fit(Xtrain, y_train)\n",
    "numPixel = list(range(dx*dy))\n",
    "\n",
    "#Obtener los valores de Score y generar un dataFrame para su representación.\n",
    "df = pd.DataFrame({'Pixeles': numPixel,'Score': Kbest.scores_.tolist()}).sort_values('Score', ascending = False)\n",
    "plot = df.Score.plot(kind = 'hist', bins=40, title='Selección de Kbest')\n",
    "plot.set_xlabel(\"Score\")\n",
    "plot.set_ylabel(\"Frecuencia\")\n",
    "\n",
    "#Seleccionar un valor de K para probar los diferentes resultados en entrenamiento, test y validacion:\n",
    "valores_K = [20, 30, 45]\n",
    "accTrain=[]\n",
    "accTest=[]\n",
    "accVal=[]\n",
    "\n",
    "for i,k in enumerate(valores_K):\n",
    "    #Seleccionar aquellos pixeles que tengan un Score mayor o igual al establecido\n",
    "    pixelesSelec = df[df.Score >= k]['Pixeles'].values.tolist()\n",
    "    regresion = LogisticRegression()\n",
    "    \n",
    "    #Entrenar el modelo con los ejemplos con el nuevo numero de caracteristicas:\n",
    "    #Generar el nuevo conjunto de Train:\n",
    "    X_train_tratada = Xtrain[:,pixelesSelec]\n",
    "    \n",
    "    #Entrenar el modelo:\n",
    "    regresion.fit(X_train_tratada,y_train)\n",
    "    \n",
    "    #Obtener la predcción en train y el accuracy:\n",
    "    predictTrain = regresion.predict(X_train_tratada)\n",
    "    accTrain.append(metrics.accuracy_score(predictTrain,y_train)*100)\n",
    "    \n",
    "    #Generar el nuevo conjunto de Val:\n",
    "    X_val_tratada = Xval[:,pixelesSelec]\n",
    "    \n",
    "    #Obtener la predcción en train y el accuracy:\n",
    "    predictVal = regresion.predict(X_val_tratada)\n",
    "    accVal.append(metrics.accuracy_score(predictVal,y_val)*100)\n",
    "    \n",
    "    #Generar el nuevo conjunto de Test:\n",
    "    X_test_tratada = Xtest[:,pixelesSelec]\n",
    "    \n",
    "    #Obtener la predcción en train y el accuracy:\n",
    "    predictTest = regresion.predict(X_test_tratada)\n",
    "    accTest.append(metrics.accuracy_score(predictTest,y_test)*100)\n",
    "    \n",
    "    print('El rendimiento en entrenamiento con {} variables es de {}%'.format(k,accTrain[i]))\n",
    "    print('El rendimiento en validacion con {} variables es de {}%'.format(k,accVal[i]))\n",
    "    print('El rendimiento en test con {} variables es de {}%'.format(k,accTest[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
